<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on My Dev Blog</title><link>https://jobcespedes.dev/posts/</link><description>Recent content in Posts on My Dev Blog</description><generator>Hugo -- gohugo.io</generator><copyright>© 2020 Job Céspedes Ortiz</copyright><lastBuildDate>Thu, 09 Nov 2023 12:00:00 -0600</lastBuildDate><atom:link href="https://jobcespedes.dev/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>Building a K3s Cluster with Armbian on Orange Pi 5 Plus</title><link>https://jobcespedes.dev/2023/11/building-a-k3s-cluster-with-armbian-on-orange-pi-5-plus/</link><pubDate>Thu, 09 Nov 2023 12:00:00 -0600</pubDate><guid>https://jobcespedes.dev/2023/11/building-a-k3s-cluster-with-armbian-on-orange-pi-5-plus/</guid><description>In this blog post, I&amp;rsquo;ll be sharing my practical journey of building a K3s Cluster on the Orange Pi 5 Plus (opi5+) using Armbian as the Operating System (OS) and Ansible. The post is meant as a straightforward guide for anyone looking to replicate the process. I hope it proves helpful for your own setup.
Please consider that in some sections, there are references to external guides containing the respective steps.</description></item><item><title>Building a K3s Cluster with Fedora CoreOS on Orange Pi 5 Plus</title><link>https://jobcespedes.dev/2023/11/building-a-k3s-cluster-with-fedora-coreos-on-orange-pi-5-plus/</link><pubDate>Thu, 09 Nov 2023 11:00:00 -0600</pubDate><guid>https://jobcespedes.dev/2023/11/building-a-k3s-cluster-with-fedora-coreos-on-orange-pi-5-plus/</guid><description>This blog post summarizes my unsuccessful attempt to build a K3s Cluster on the Orange Pi 5 Plus (opi5+) using Fedora CoreOS (FCOS). It also outlines the steps taken before arriving at that conclusion and presents a list of possible alternatives to achieve a similar result.
Why Fedora CoreOS? The main reasons behind selecting FCOS as the Operating System (OS) were:
Automatic Updates: Fedora CoreOS follows an automated update model, and reboots can also be orchestrated using Zincati.</description></item><item><title>Running Virtual Machines on Orange Pi 5</title><link>https://jobcespedes.dev/2023/11/running-virtual-machines-on-orange-pi-5/</link><pubDate>Thu, 09 Nov 2023 09:00:00 -0600</pubDate><guid>https://jobcespedes.dev/2023/11/running-virtual-machines-on-orange-pi-5/</guid><description>In this guide, we&amp;rsquo;ll walk through the steps to install libvirt on the Single Board Computer (SBC) Orange Pi 5 (opi5) for running virtual machines (VMs). I&amp;rsquo;ve compiled these steps after dealing with the opi5 instructions, searching on the internet and communities, and my own experience. I hope this guide helps someone accomplish this task more quickly than I did initially.
Installing Orange Pi 5 The first step is to install an Operating System (OS) on the opi5.</description></item><item><title>A KeyDB Operator</title><link>https://jobcespedes.dev/2022/01/a-keydb-operator/</link><pubDate>Sat, 22 Jan 2022 23:00:00 -0600</pubDate><guid>https://jobcespedes.dev/2022/01/a-keydb-operator/</guid><description>KeyDB is a multithreading, drop-in alternative to Redis. The Keydb-operator can easily create either a standalone instance (1 replica) or a multimaster setup (3 replicas) of the KeyDB in-memory database. When KeyDB is in multimaster mode, it is possible to have more than one master, allowing for read/write operations across all of them. This capability enhances high availability and fault tolerance.
This operator is part of the Kubernetes operators and tools developed by Krestomatio, a managed service for Moodle™ instances</description></item><item><title>A Kubernetes NFS Operator</title><link>https://jobcespedes.dev/2021/07/a-kubernetes-nfs-operator/</link><pubDate>Fri, 02 Jul 2021 13:55:42 -0600</pubDate><guid>https://jobcespedes.dev/2021/07/a-kubernetes-nfs-operator/</guid><description>NFS Operator creates NFSv4 ganesha servers in Kubernetes, allowing to set ownership/permissions of their NFS export directory; to autoexpand their PVC; and to enable RWX storage from them:
It can set ownership and permissions for export parent directory of the (NFS) Ganesha server. It is able to expand/adjust the PVC size of the (NFS) Ganesha server automatically, as it grows. It could autogenerate an StorageClass that uses the (NFS) Ganesha server for RWX storage.</description></item><item><title>A Minimal Container Image for Rocky Linux 8</title><link>https://jobcespedes.dev/2021/06/a-minimal-container-image-for-rocky-linux-8/</link><pubDate>Fri, 25 Jun 2021 18:55:42 -0600</pubDate><guid>https://jobcespedes.dev/2021/06/a-minimal-container-image-for-rocky-linux-8/</guid><description>Now that Rocky Linux is GA, here is a repo for a minimal container image for Rocky Linux. Its size is around ~37 MB (compressed). It is based on Fedora Minimal and UBI8 minimal from Red Hat. You can download it from Quay or build it, following the instructions in the repo. You could also generate a new rootfs yourself before building the image, again, following the short instructions in the repo.</description></item><item><title>Simple Testing of Complex Scenarios</title><link>https://jobcespedes.dev/2020/05/simple-testing-of-complex-scenarios/</link><pubDate>Thu, 21 May 2020 18:14:42 -0600</pubDate><guid>https://jobcespedes.dev/2020/05/simple-testing-of-complex-scenarios/</guid><description>Is there something easy when deploying and configuring the database layer?
Aspects of Data integrity and reliable/safe operations add up to complexity, which only increases when tradicional SQL, high availability, fault tolerance, scalability and high levels of concurrency, are required. It is a sensitive layer, no doubt. Consequently, if there is something easy there, it would be to screw everything up.
Do not fear, go test, screw up and learn. I mean, just not in production.</description></item><item><title>alias docker=podman</title><link>https://jobcespedes.dev/2020/03/alias-docker-podman/</link><pubDate>Mon, 02 Mar 2020 10:48:50 -0600</pubDate><guid>https://jobcespedes.dev/2020/03/alias-docker-podman/</guid><description>I have heard about podman (Pod Manager tool) more and more often now. Whether it is that I have come closer to its developing environment or that it has come to mine, I&amp;rsquo;m not sure. It&amp;rsquo;s both, I guess. I use Ansible a lot for automating baremetal and virtual infrastructure: for its definition, deployment, configuration, operation, among other things. In the recent years, I have being using more and more containers, particularly in the developing stages.</description></item><item><title>Multiple Environments in Ansible</title><link>https://jobcespedes.dev/2020/02/multiple-environments-in-ansible/</link><pubDate>Thu, 27 Feb 2020 14:14:42 -0600</pubDate><guid>https://jobcespedes.dev/2020/02/multiple-environments-in-ansible/</guid><description>Many systems are deployed in a multienvironment context, for example: production, stage, and dev. These environments often share variables and artifacts. In Ansible, there are different methods to work in this context. For example, separate directory layout and soft links. However, it can end with a considerable amount of data and duplicate files between environments, exposing variables to all hosts or adding much more complexity to playbooks.
Demo multienv tests a stackable multienvironment directory layout for Ansible, using multienv Ansible role.</description></item></channel></rss>